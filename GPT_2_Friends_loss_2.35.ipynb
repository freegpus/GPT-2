{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gyCMja0TFzON"
   },
   "source": [
    "# Using GPT-2 to Create the 'Secret' Friends Episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyQsY27KGk4p"
   },
   "source": [
    "[GPT-2 Simple](https://github.com/minimaxir/gpt-2-simple) is the only dependency we'll need to get going. It is basically a customized GPT-2 that allows us to 'fine tune' the text using data of our choosing. It only works with Tensorflow ver <=1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "colab_type": "code",
    "id": "J5kD1EmVNMth",
    "outputId": "57de6c48-9b62-4897-c4d0-e7a8e91af554"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.6/dist-packages (0.7.1)\n",
      "Requirement already satisfied: toposort in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.5)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (4.28.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (1.17.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gpt-2-simple) (2.21.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
      "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
      "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.17.5)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.27.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.1.8)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.11.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.2.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (45.1.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gpt-2-simple\n",
    "!pip install tensorflow==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "colab_type": "code",
    "id": "zICi4wqRGMZm",
    "outputId": "1791690c-6c04-4da9-da19-95274ac0c4e3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gpt_2_simple as gpt2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tf78oDHjMKmM"
   },
   "source": [
    "We need to download the proper GPT-2 model first.\n",
    "\n",
    "There are three released sizes of GPT-2:\n",
    "\n",
    "124M (default): the \"small\" model, 500MB on disk.\n",
    "355M: the \"medium\" model, 1.5GB on disk.\n",
    "774M: the \"large\" model, can't be fine tuned in Colab.\n",
    "1558M: the \"extra large\", true model also can't be fine tuned in Colab.\n",
    "\n",
    "The best model for fine tuning in colab and easiest to work with is the 124M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "4aUT7ohVHGRs",
    "outputId": "f018a2dd-a951-440c-9643-8c4140ae4616"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching checkpoint: 1.05Mit [00:00, 504Mit/s]                                                      \n",
      "Fetching encoder.json: 1.05Mit [00:00, 101Mit/s]                                                    \n",
      "Fetching hparams.json: 1.05Mit [00:00, 398Mit/s]                                                    \n",
      "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:01, 250Mit/s]                                   \n",
      "Fetching model.ckpt.index: 1.05Mit [00:00, 309Mit/s]                                                \n",
      "Fetching model.ckpt.meta: 1.05Mit [00:00, 132Mit/s]                                                 \n",
      "Fetching vocab.bpe: 1.05Mit [00:00, 183Mit/s]                                                       \n"
     ]
    }
   ],
   "source": [
    "gpt2.download_gpt2(model_name=\"124M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "au9R2TqxOZls"
   },
   "source": [
    "Mount google drive and load the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "puq4iC6vUAHc",
    "outputId": "d742b6bc-2744-42e4-ce21-64478bc7d677"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "gpt2.mount_gdrive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_dsknq0MpJQ"
   },
   "outputs": [],
   "source": [
    "# I used seasons 1 & 3, with other random episodes throughout\n",
    "text_location = \"friends_script.txt\"\n",
    "gpt2.copy_file_from_gdrive(text_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Ym5QRF1PLOS"
   },
   "source": [
    "## Finetune GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3RXSvqzwPRiF"
   },
   "source": [
    "Now for the longest and most important step, we have to finetune the GPT-2 model with our data (to run indefinitely, set steps = -1).\n",
    "\n",
    "The model checkpoints will be saved in /checkpoint/chkpt1 by default. We have it set up to save the checkpoints every 100 steps. If you rerun this cell, you might need to restart the kernel.\n",
    "\n",
    "restore_from: Set to 'fresh' to start training from the base GPT-2, or set to 'latest' to restart training from an existing checkpoint.\n",
    "\n",
    "sample_every: Number of steps to print example output\n",
    "\n",
    "print_every: Number of steps to print training progress.\n",
    "\n",
    "learning_rate: Learning rate for the training (lower to 1e-5 if you have <1MB input data)\n",
    "\n",
    "run_name: subfolder within checkpoint to save the model (will also need to specify run_name when loading the model)\n",
    "\n",
    "overwrite: Set to 'True' if you want to continue finetuning an existing model (make sure to also set restore_from='latest') without creating duplicate copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "colab_type": "code",
    "id": "pdQVC2QdO-g0",
    "outputId": "614746f7-86c5-42c8-c4aa-83dce535d0ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Loading checkpoint checkpoint/chkpt1/model-45\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/chkpt1/model-45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 324674 tokens\n",
      "Training...\n",
      "Saving checkpoint/chkpt1/model-45\n",
      "[50 | 387.17] loss=2.23 avg=2.23\n",
      "Saving checkpoint/chkpt1/model-50\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:960: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "[60 | 1150.46] loss=2.35 avg=2.29\n",
      "[70 | 1917.28] loss=2.34 avg=2.31\n",
      "[80 | 2669.83] loss=2.47 avg=2.35\n",
      "interrupted\n",
      "Saving checkpoint/chkpt1/model-82\n"
     ]
    }
   ],
   "source": [
    "sess = gpt2.start_tf_sess()\n",
    "\n",
    "gpt2.finetune(sess,\n",
    "              dataset=text_location,\n",
    "              model_name='124M',\n",
    "              steps=500,\n",
    "              restore_from='latest',\n",
    "              run_name='chkpt1',\n",
    "              print_every=10,\n",
    "              sample_every=250,\n",
    "              save_every=50,\n",
    "              overwrite = True\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dohqx1nIsEfX"
   },
   "source": [
    "## Loss\n",
    "\n",
    "Something worth noting is the loss and the average loss. While the loss at the point of iteration is not important, the average IS important. It needs to be constantly going down. If it starts going back up, that means the model has 'converged' and the model won't get any better based on the data it's working with. In this scenario, it looks like step 50 was the lowest the loss was, and it's creeping back up. This makes sense becuase we only have it 1 MB worth of text training. I stopped the training at step 82. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ewnfApBPgFz"
   },
   "source": [
    "Save the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CGfGEEz4PhiT"
   },
   "outputs": [],
   "source": [
    "gpt2.copy_checkpoint_to_gdrive(run_name=\"chkpt1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioAz-Cs_P3yg"
   },
   "source": [
    "Generate from saved checkpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Zw9zVAehP6I_",
    "outputId": "093d64cc-0fe5-46a3-eecc-965253f131ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Scene: Monica and Joey are sitting on coffee shop couch reading My Life by Bill Clinton]\n",
      "Ross: No! No!\n",
      "Chandler: No! No!\n",
      "Ross: No, no, no, no!\n",
      "Chandler: No, no, no, no!\n",
      "Ross: No, no, no, no, no!\n",
      "Chandler: No, no, no, no, no!\n",
      "Ross: No, no, no, no, no!\n",
      "Chandler: No, no, no, no, no!\n",
      "Ross: No, no, no, no, no!\n",
      "Chandler: No, no, no, no, no!\n",
      "Ross: No, no, no, no, no!\n",
      "Chandler: No, no, no, no, no, no!\n",
      "Ross: No, no, no, no, no!\n",
      "Chandler: No, no, no, no, no, no!\n",
      "Ross: No, no, no, no, no, no!\n",
      "Chandler: No, no, no, no, no, no, no!\n",
      "Ross: No, no, no, no, no, no!\n",
      "Chandler: No, no, no, no, no, no, no!\n",
      "Ross: No, no, no, no, no, no!\n",
      "Chandler: No, no, no, no, no, no, no!\n",
      "Ross: No, no, no, no, no, no!\n",
      "Chandler: No, no, no, no, no, no, no!\n",
      "Ross: No, no, no, no, no, no, no!\n",
      "Chandler: No, no, no, no, no, no, no!\n",
      "Ross: No, no, no, no, no, no, no, no!\n",
      "====================\n",
      "[Scene: Monica and Joey are sitting on coffee shop couch reading My Life by Bill Clinton]\n",
      " \n",
      "Monica: Hey!\n",
      "Joey: Hey, you wanna date me?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Monica: Yeah!\n",
      "Joey: Can I get you a cup of coffee?\n",
      "Mon\n",
      "====================\n",
      "[Scene: Monica and Joey are sitting on coffee shop couch reading My Life by Bill Clinton]\n",
      "Chandler: You guys, Monica, were you thinking that maybe you could only get one answer?\n",
      "Monica: I'm thinking that maybe I should just hook up with Monica.\n",
      "Chandler: How can you not think of that?\n",
      "Monica: Well, I am, uh, I am.\n",
      "Chandler: You know, I don't think I should let you do that.\n",
      "Monica: But, uh, I'm not saying that you shouldn't, okay?\n",
      "Chandler: No. I'm telling you, um, I'm not saying that, I'm just saying that, I mean, I just feel the need to tell you that I'm not okay with this whole thing.\n",
      "Monica: God, you're not okay with this?\n",
      "Chandler: I am. I'm not!!\n",
      "Monica: Well, I'm sorry, I'm sorry, I'm sorry, we're not the same.\n",
      "Chandler: Well, we are. We are. And we love each other.\n",
      "Phoebe: Okay, I'm done...I'm going to break this up with you.\n",
      "Monica: Oh! What?\n",
      "Phoebe: You broke up with her?\n",
      "Monica: No.\n",
      "Phoebe: You broke up with her?!\n",
      "Monica: No, no...no, that's not the point.\n",
      "Phoebe: You broke up with her!\n",
      "Monica: No, no, I don't?!\n",
      "Phoebe: No, no, no, no.\n",
      "Monica: ...No, no, no...No, no, no...\n",
      "Phoebe: No, no, no!\n",
      "Monica: No, no, no!\n",
      "Phoebe: No, no, no\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "gpt2.generate(sess, run_name=\"chkpt1\", \n",
    "              length=400,\n",
    "              temperature=0.7,\n",
    "              prefix=\"[Scene: Monica and Joey are sitting on coffee shop couch reading My Life by Bill Clinton]\",\n",
    "              nsamples=3,\n",
    "              batch_size=3)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GPT-2_Friends.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
